{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business = pd.read_json(\"yelp_academic_dataset_business.json\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sneak peek into 2 first rows to realise what we've got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 2 bool arrays to finaly get only Austing AND Texas entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "austin_tx_bool = np.array(business.city == 'Austin') * np.array(business.state == 'TX')\r\n",
    "austin_tx = business[austin_tx_bool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# austin_tx.to_json('austin_tx.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop unimportant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# austin_tx = austin_tx.drop(['city', 'state', 'business_id', 'address'], axis=1)\r\n",
    "austin_tx = austin_tx.drop(['city', 'state', 'business_id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a lot of nan values, let's see how many."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "austin_tx.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop the nans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped = austin_tx.shape[0]\r\n",
    "austin_tx.dropna(inplace=True)\r\n",
    "dropped -= austin_tx.shape[0]\r\n",
    "print(\"Dropped:\", dropped, \"rows with nan values.\") #5070"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# austin_tx.to_json('austin_tx_nona.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's peek to first 2 rows to see what we've got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "austin_tx.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a column stating distance in... kinda minutes in GPS sense I guess... Doesn't really matter - what matters is we can compare distances from the centre now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_lon_df = austin_tx.loc[:,'latitude':'longitude']\r\n",
    "number_of_rows = lat_lon_df.shape[0]\r\n",
    "\r\n",
    "gps_based_distance = np.zeros(shape=number_of_rows)\r\n",
    "\r\n",
    "for row in np.arange(number_of_rows):\r\n",
    "\r\n",
    "    lat_lon = np.array([lat_lon_df.iloc[row][0], lat_lon_df.iloc[row][1]]) * 60\r\n",
    "    capitol_lat_lon = np.array([30.274773446583634, -97.74038126660496]) * 60\r\n",
    "    gps_based_distance[row] = np.linalg.norm(lat_lon - capitol_lat_lon)\r\n",
    "\r\n",
    "austin_tx['dist_from_center'] = gps_based_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear address column from strange informations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_address(address):\r\n",
    "    return (address.split(sep=', '))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "austin_tx['address'] = austin_tx['address'].apply(fix_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "austin_tx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work In progress - function to get all the distances from a given location to given addressess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\r\n",
    "from geopy.distance import distance\r\n",
    "\r\n",
    "def get_distances(dataframe, addresses_column_name, given_location, postifx=\"\", inplace=False): # TODO: add mechanics for inplace=True\r\n",
    "    \"\"\"\r\n",
    "    dataframe - pandas.DataFrame object\r\n",
    "    addresses_column_name - name of the column in which we can find addresses\r\n",
    "    given_location - tuple with latitude and longitude of a location from which we're counting the distance\r\n",
    "\r\n",
    "    postfix - what should I add to every address to make sure it's what we need. example: city/country\r\n",
    "\r\n",
    "    returned value - pd.Series distances in kilometers\r\n",
    "    \"\"\"\r\n",
    "    geolocator = Nominatim(user_agent=\"Strive School YMVC Project\")\r\n",
    "\r\n",
    "    number_of_rows = dataframe.shape[0]\r\n",
    "    addresses_df = dataframe[addresses_column_name]\r\n",
    "\r\n",
    "    gps_addresses = np.zeros(shape=number_of_rows)\r\n",
    "\r\n",
    "    for row_nr in np.arange(0, 50):  ## TODO: fix this for the real rannge, this is a testing one\r\n",
    "        dist = np.nan\r\n",
    "        try:\r\n",
    "            loc = geolocator.geocode(addresses_df.iloc[row_nr] + postifx)\r\n",
    "            dist = distance(given_location, (loc.latitude, loc.longitude)).kilometers\r\n",
    "        except Exception as e:\r\n",
    "            print(e)\r\n",
    "        gps_addresses[row_nr] = dist\r\n",
    "        \r\n",
    "    return pd.Series(gps_addresses, name=\"distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_here = (30.274773446583634, -97.74038126660496)\r\n",
    "x = get_distances(austin_tx, 'address', from_here, postifx=\" Austin Texas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[15:18]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful function to help with selecting only rows which contain a chosen word in a given column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains(column, word):\r\n",
    "    \"\"\"\r\n",
    "    Usage:\r\n",
    "    Pass a column and a word u want to find in the cells, to get a np.array of type bool.\r\n",
    "    Afterwards u can pass it as an argument of [] selection mechanism. Examples:\r\n",
    "\r\n",
    "    austin_tx[ contains(austin_tx.categories, \"Shopping\") ]\r\n",
    "    austin_tx[ contains(austin_tx.categories, \"Shopping\") | contains(austin_tx.categories, \"Hotels\") ]      # and\r\n",
    "    austin_tx[ contains(austin_tx.categories, \"Shopping\") & contains(austin_tx.categories, \"Watches\") ]     # or\r\n",
    "\r\n",
    "    Works for all columns that return strings. hours and attributes too.\r\n",
    "    \"\"\"\r\n",
    "    return np.array([(word in vals) for vals in column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chech for ALL existing cathegories. (Additionaly it checks how many of each one are there.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_counts = {}\r\n",
    "for things in austin_tx.categories.unique():\r\n",
    "    things = things.replace(', &', ' &')\r\n",
    "    for thing in things.split(sep=\", \"):\r\n",
    "        if thing in categories_counts.keys():\r\n",
    "            categories_counts[thing] += 1\r\n",
    "        else:\r\n",
    "            categories_counts[thing] = 1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0b3835b907b6cc7d301aec5540e8a0fbdbe5019d215ce85ebb6eb02d9dcf944e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('numba': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}