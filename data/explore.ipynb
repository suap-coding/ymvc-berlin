{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business = pd.read_json(\"yelp_academic_dataset_business.json\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sneak peek into 2 first rows to realise what we've got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 2 bool arrays to finaly get only Austing AND Texas entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "austin_tx_bool = np.array(business.city == 'Austin') * np.array(business.state == 'TX')\r\n",
    "austin_tx = business[austin_tx_bool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# austin_tx.to_json('austin_tx.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop unimportant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# austin_tx = austin_tx.drop(['city', 'state', 'business_id', 'address'], axis=1)\r\n",
    "austin_tx = austin_tx.drop(['city', 'state', 'business_id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a lot of nan values, let's see how many."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "austin_tx.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop the nans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped = austin_tx.shape[0]\r\n",
    "austin_tx.dropna(inplace=True)\r\n",
    "dropped -= austin_tx.shape[0]\r\n",
    "print(\"Dropped:\", dropped, \"rows with nan values.\") #5070"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# austin_tx.to_json('austin_tx_nona.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's peek to first 2 rows to see what we've got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "austin_tx.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to add distances from given place to the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear address column from strange informations, this fix_adress() is suited for austin_tx database. New one may be required for Berlin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_address(address):\r\n",
    "    return (address.split(sep=', '))[0]\r\n",
    "austin_tx['address'] = austin_tx['address'].apply(fix_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "austin_tx.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual function to use in our work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge geopy\r\n",
    "from geopy.geocoders import Nominatim\r\n",
    "from geopy.distance import distance\r\n",
    "\r\n",
    "# proceed with cauction!!!\r\n",
    "def distance_from(dataframe, addresses_column_name, given_location, postifx=\"\", inplace=False):\r\n",
    "    \"\"\"\r\n",
    "    dataframe - pandas.DataFrame object\r\n",
    "    addresses_column_name - name of the column in which we can find addresses\r\n",
    "    given_location - tuple with latitude and longitude of a location from which we're counting the distance\r\n",
    "\r\n",
    "    postfix - what should I add to every address to make sure it's what we need. example: city/country\r\n",
    "    inplace - check it if you want to change the given dataframe. default False\r\n",
    "\r\n",
    "    returned value - pd.Series distances in kilometers\r\n",
    "    \"\"\"\r\n",
    "    geolocator = Nominatim(user_agent=\"Strive School YMVC Project\")\r\n",
    "\r\n",
    "    number_of_rows = dataframe.shape[0]\r\n",
    "    addresses_df = dataframe[addresses_column_name]\r\n",
    "\r\n",
    "    gps_addresses = np.zeros(shape=number_of_rows)\r\n",
    "\r\n",
    "    # this loop can take a looooong time.\r\n",
    "    for row_nr in np.arange(0, number_of_rows):\r\n",
    "        dist = np.nan\r\n",
    "        try:\r\n",
    "            loc = geolocator.geocode(addresses_df.iloc[row_nr] + postifx)\r\n",
    "            dist = distance(given_location, (loc.latitude, loc.longitude)).kilometers\r\n",
    "        except Exception as e:\r\n",
    "            print(e)\r\n",
    "        gps_addresses[row_nr] = dist\r\n",
    "\r\n",
    "    if inplace:\r\n",
    "        # we put a new column before the \"address\" column\r\n",
    "        dataframe.insert(dataframe.columns.get_loc(addresses_column_name), 'distance_km', gps_addresses)\r\n",
    "    else:\r\n",
    "        return pd.Series(gps_addresses, name='distance_km')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of use with inplace=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary dataframe\r\n",
    "head_2 = austin_tx.head(2)\r\n",
    "\r\n",
    "# some coordinates\r\n",
    "some_place = (30.274773446583634, -97.74038126660496)\r\n",
    "\r\n",
    "pd_series_distance = distance_from(head_2, 'address', some_place, postifx=\" Austin Texas\", inplace=False)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distances stored outside the given dataframe\r\n",
    "pd_series_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe unchanged\r\n",
    "head_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example use with inplace=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_from(head_2, 'address', some_place, postifx=\" Austin Texas\", inplace=True)\r\n",
    "# returned value: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head_2 has new column: distance_km\r\n",
    "head_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for indexing dataframes based on strings/string parts that are contained in given column.\r\n",
    "(This function is just a mechanism we can use for boolean-indexing the dataframe since it returns boolean array.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains(column, word):\r\n",
    "    \"\"\"\r\n",
    "    Usage:\r\n",
    "    Pass a column and a word u want to find in the cells, to get a np.array of type bool.\r\n",
    "    Afterwards u can pass it as an argument of [] selection mechanism. Examples:\r\n",
    "\r\n",
    "    austin_tx[ contains(austin_tx.categories, \"Shopping\") ]\r\n",
    "    austin_tx[ contains(austin_tx.categories, \"Shopping\") | contains(austin_tx.categories, \"Hotels\") ]      # and\r\n",
    "    austin_tx[ contains(austin_tx.categories, \"Shopping\") & contains(austin_tx.categories, \"Watches\") ]     # or\r\n",
    "\r\n",
    "    Works for all columns that return strings. hours and attributes too.\r\n",
    "    \"\"\"\r\n",
    "    return np.array([(word in vals) for vals in column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: get all Shops that do Watches. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(austin_tx[ contains(austin_tx.categories, \"Shopping\") & contains(austin_tx.categories, \"Watches\") ]).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function that returns all categories and how much of each there is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear categories column from strange informations, this fix_category() is suited for austin_tx database. New one may be required for Berlin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_category(category):\r\n",
    "    return category.replace(\", &\", \" &\")\r\n",
    "austin_tx['categories'] = austin_tx['categories'].apply(fix_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categories_dict(category_column):\r\n",
    "    categories_counts = {}\r\n",
    "    for things in category_column:\r\n",
    "        for thing in things.split(sep=\", \"):    \r\n",
    "            if thing in categories_counts.keys():\r\n",
    "                categories_counts[thing] += 1\r\n",
    "            else:\r\n",
    "                categories_counts[thing] = 1\r\n",
    "    return categories_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_counts = get_categories_dict(austin_tx['categories'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use the loop below to just show first 3 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# few example entries in \"categories_counts\"\r\n",
    "for idx, key in enumerate(categories_counts):\r\n",
    "    if idx < 3:\r\n",
    "        print(\"Category name:\", key, \"\\nNumber of entries with this type:\", categories_counts[key], \"\\n\")\r\n",
    "    else:\r\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the line below and run this cell if you wanna see EVERYTHING\r\n",
    "# categories_counts"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0b3835b907b6cc7d301aec5540e8a0fbdbe5019d215ce85ebb6eb02d9dcf944e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('numba': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}