{"cells":[{"cell_type":"markdown","metadata":{},"source":["# MOVIES PROJECT"]},{"cell_type":"markdown","metadata":{},"source":["necesary imports"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import requests\n","from bs4 import BeautifulSoup\n","import re"]},{"cell_type":"markdown","metadata":{},"source":["get responses from lots of urls <br>\n","starting with: <br>\n","https://www.imdb.com/...&start=1 <br>\n","up to: <br>\n","https://www.imdb.com/...&start=6651"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["responses = []\n","# for position in range(1, 6652, 50):\n","for position in range(1, 152, 50):\n","    request = requests.get(\n","        f\"https://www.imdb.com/search/title/?title_type=feature&num_votes=10000,&countries=us&sort=user_rating,desc&start={position}\"\n","    )\n","    responses.append(request)\n","len(responses)"]},{"cell_type":"markdown","metadata":{},"source":["sopify all of them"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["soups = []\n","for response in responses:\n","    soups.append(BeautifulSoup(response.text, 'html.parser'))\n","len(soups)\n"]},{"cell_type":"markdown","metadata":{},"source":["## RELEASE DATES"]},{"cell_type":"markdown","metadata":{},"source":["date cleaning function"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def extract_int(string):\n","    return re.search(r\"\\d+\", string).group()"]},{"cell_type":"markdown","metadata":{},"source":["traverse the soups in search for dates, create a list of them, serialise it"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["movie_release_dates = []\n","for soup in soups:\n","    movie_release_dates += soup.findAll('span', class_= 'lister-item-year text-muted unbold')\n","\n","rel_dates_list = []\n","for str_date in movie_release_dates:\n","    rel_dates_list.append( extract_int(str_date.text) )\n","\n","rel_dates_series = pd.Series(rel_dates_list, name=\"Release Date\")\n","rel_dates_series"]},{"cell_type":"markdown","metadata":{},"source":["## RUNTIMES"]},{"cell_type":"markdown","metadata":{},"source":["create a time-cleaning function"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def clean_time(time_string):\n","\n","    time_string = time_string.split()\n","    time_string = time_string[0]\n","\n","    return int(time_string)"]},{"cell_type":"markdown","metadata":{},"source":["traverse the soups in search for runtimes, create a list of them, serialise it"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["runtimes = []\n","for soup in soups:\n","    runtimes += soup.findAll('span', class_=\"runtime\")\n","\n","movie_runtimes = []\n","for runtime in runtimes:\n","    movie_runtimes.append( clean_time(runtime.text) )\n","runtimes_series = pd.Series(movie_runtimes, name=\"Runtime\")\n","\n","runtimes_series"]},{"cell_type":"markdown","metadata":{},"source":["## MOVIE NAMES\n","and addresses for details pages"]},{"cell_type":"markdown","metadata":{},"source":["traverse the soups in search for movie names and urls, create a list of them, serialise it"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["movie_headers = []\n","for soup in soups:\n","    movie_headers += soup.find_all(name=\"h3\", class_=\"lister-item-header\")\n","\n","names_list = []\n","hrefs_list = []     # this is very important for later. they look like this: '/title/tt0111161/'\n","for header in movie_headers:\n","    names_list.append(header.contents[3].text)\n","    hrefs_list.append(header.contents[3]['href'] )\n","\n","names_series = pd.Series(names_list, name=\"Movie name\")\n","names_series"]},{"cell_type":"markdown","metadata":{},"source":["## FILMING DATES\n","this may be tricky"]},{"cell_type":"markdown","metadata":{},"source":["first we get the responses for all the 6600+ movies... "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["href_responses = []\n","# hl = hrefs_list[:1]\n","for href in hrefs_list:\n","    request = requests.get(\n","        f\"https://www.imdb.com{href}locations\"\n","    )\n","    href_responses.append(request)\n","len(href_responses)"]},{"cell_type":"markdown","metadata":{},"source":["now let's soupify them..."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["href_soups = []\n","for response in href_responses:\n","    href_soups.append(BeautifulSoup(response.text, 'html.parser'))\n","len(href_soups)"]},{"cell_type":"markdown","metadata":{},"source":["and start digging for dates..."]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["filming_dates = []\n","for idx, soup in enumerate(href_soups):\n","    date = soup.find(name=\"section\", id=\"filming_dates\")\n","    filming_dates.append(date)\n","len(filming_dates)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for idx, date in enumerate(filming_dates):\n","    print(idx, date.contents[3].text.strip())"]},{"cell_type":"markdown","metadata":{},"source":["## MOVIE TYPES"]},{"cell_type":"markdown","metadata":{},"source":["traverse the soups in search for movie names, clean them, create a list of them and serialise it"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["genres = []\n","\n","for soup in soups:\n","    genres += soup.find_all(name=\"span\", class_=\"genre\")\n","\n","genres_list = []\n","for gen in genres:\n","    string = list(gen)[0].replace(\"\\n\", \"\").strip()\n","    genres_list.append(string)\n","\n","genres_series = pd.Series(genres_list, name=\"Genre\")\n","genres_series"]},{"cell_type":"markdown","metadata":{},"source":["## RATING"]},{"cell_type":"markdown","metadata":{},"source":["traverse the soup, get stuff from it and serialise it in 2 steps"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# <div class=\"inline-block ratings-imdb-rating\" name=\"ir\" data-value=\"8,3\">\n","ratings = []\n","for soup in soups:\n","    ratings += soup.find_all(name=\"div\", attrs={'name':'ir'})\n","\n","ratings_series = pd.Series([ float(rt.text.strip()) for rt in ratings ], name=\"Rating\")\n","ratings_series"]},{"cell_type":"markdown","metadata":{},"source":["## PROFIT!"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["all_series = [names_series, ratings_series, rel_dates_series, runtimes_series, genres_series]\n","\n","df = pd.concat(all_series, axis=1)\n","\n","# %timeit df.loc[df.loc[:,'Genre'].str.contains('Action')]\n","# %timeit df.loc[df['Genre'].str.contains('Action')]\n","# %timeit df.loc[ [('Action' in genre) for genre in df.loc[:,'Genre']]]\n","# %timeit df.loc[ [('Action' in genre) for genre in df['Genre']]]\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df"]},{"cell_type":"markdown","metadata":{},"source":["extract action movies"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["action = df.loc[ [('Action' in genre) for genre in df['Genre']]]\n","action"]}],"metadata":{"interpreter":{"hash":"5f25a9e58d7059a5bce325f0d5c81f23f5b8f1e91d7d17950277ab26020b5adf"},"kernelspec":{"display_name":"Python 3.9.5 64-bit ('webscrapping': conda)","name":"python3"},"language_info":{"name":"python","version":""}},"nbformat":4,"nbformat_minor":2}